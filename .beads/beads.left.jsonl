{"id":"moral_decision_consistency-1g8","content_hash":"84cf89d785bbf95b7be0cac3f88819377c9f24787e0c9bb672883ca299c892c1","title":"Extend verify_setup.py to check local model connectivity","description":"Priority: Medium\nArea: Setup verification, local models\n\nProblem:\nverify_setup.py currently checks imports, configs, and mock providers but never exercises Ollama/Qwen, so local misconfiguration only shows up during experiments.\n\nScope:\n- scripts/verify_setup.py\n- config/models.yaml\n\nTasks:\n- Load models config and detect configured ollama/vllm entries.\n- When the Qwen3 ollama model exists, attempt a light connectivity check (e.g., provider.validate_connection() or short generate).\n- Emit success/warning messages like \"✓ Ollama/Qwen3 reachable\" or \"⚠ Ollama/Qwen3 not reachable; is Ollama running?\" without failing the entire script.\n\nAcceptance:\n- verify_setup.py reports a successful connectivity check when Ollama + Qwen3 are running.\n- When Ollama is down or the model is missing, the script prints a clear warning while other checks still complete.","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-19T14:37:32.642481+08:00","updated_at":"2025-11-19T14:37:32.642481+08:00","source_repo":"."}
{"id":"moral_decision_consistency-90x","content_hash":"54b7bc3fbc09137a874c707a0fce0895946ffed4cfa2a13d0d3acc306d245ece","title":"Enable config-driven provider mapping so Ollama/Qwen3 can be used in experiments","description":"Priority: High\nArea: Provider selection, configuration\n\nProblem:\nget_provider_from_model_name in src/models/__init__.py forces qwen -\u003e vllm so models defined under config/models.yaml \u003e ollama can never be instantiated. Local Qwen3 via Ollama stays unusable even when configured.\n\nScope:\n- src/models/__init__.py\n- src/experiments/phase1_consistency.py\n- src/experiments/phase2_perturbation.py\n- src/config/loader.py\n\nTasks:\n- Add helper that loads config/models.yaml via ConfigLoader and returns the provider section that declares the requested model.\n- Update Phase 1 and Phase 2 runners to call helper and fall back to heuristic only if model missing from config.\n- Keep provider init errors informative when a model is absent from config.\n\nAcceptance:\n- Adding qwen3-14b-q5 under ollama.models and referencing it in pilot.models instantiates OllamaProvider instead of LocalVLLMProvider.\n- python scripts/run_experiment.py --phase pilot with models [\"qwen3-14b-q5\"] completes provider init and logs provider ollama.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-19T14:36:47.275922+08:00","updated_at":"2025-11-19T15:14:01.249848+08:00","closed_at":"2025-11-19T15:14:01.249848+08:00","source_repo":"."}
{"id":"moral_decision_consistency-9js","content_hash":"dc69ffd4ad819ec8b095db1b24218faea0eccd64b3f15fcad55d1320bb8c25c8","title":"Document the pilot workflow with Qwen3 14B Q5 via Ollama","description":"Priority: Medium\nArea: Documentation (SETUP.md, README.md)\n\nProblem:\nSETUP.md only references llama3 for Ollama examples and there is no explicit walkthrough for the agreed Qwen3 local pilot, leaving contributors unsure how to run it end-to-end.\n\nScope:\n- SETUP.md\n- README.md\n\nTasks:\n- Add a \"Pilot with Qwen3 14B Q5 via Ollama\" subsection detailing pulling the model, confirming config entries, running verify_setup.py, and executing the pilot (direct config or --models override once available).\n- Optionally add a README pointer in the Local Models / Quick start sections.\n\nAcceptance:\n- Following the new SETUP.md subsection from a clean machine plus Ollama is sufficient to run the local pilot without code edits.\n- README references the new workflow so local-first plan is obvious.","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-19T14:37:43.703823+08:00","updated_at":"2025-11-19T14:37:43.703823+08:00","source_repo":"."}
{"id":"moral_decision_consistency-pkx","content_hash":"f17a488cb1e4fac5cdd7842f4cc9244fa70c367ae63b6eb241dbc16ba92f5798","title":"Add Qwen3 14B Q5 Ollama config and switch the pilot to the local model","description":"Priority: High\nArea: Configuration\n\nProblem:\nDECISIONS.md mandates the pilot use Qwen3 14B Q5 via Ollama, but config/models.yaml still has only generic local placeholders and config/experiment.yaml keeps cloud pilots.\n\nScope:\n- config/models.yaml\n- config/experiment.yaml\n\nTasks:\n- Add a concrete qwen3-14b-q5 entry under ollama.models with appropriate metadata (name, supports_seed, default_max_tokens, etc.).\n- Update pilot.models to reference only the new Qwen model so the local-first pilot aligns with decisions.\n- Optionally annotate how to re-add clouds later.\n\nAcceptance:\n- With Ollama running and Qwen3 pulled, python scripts/run_experiment.py --phase pilot succeeds using only the local Qwen model.\n- Stored experiment config lists only the Qwen3 entry in models.","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-19T14:37:00.776851+08:00","updated_at":"2025-11-19T14:37:00.776851+08:00","source_repo":"."}
{"id":"moral_decision_consistency-s3f","content_hash":"406fd86d04834a257003510d14ff7a33627649c1798abf540860f5ee026722d7","title":"Add requests to dependencies and setup checks so local providers import cleanly","description":"Priority: High\nArea: Dependencies, setup verification\n\nProblem:\nsrc/models/local_model.py imports requests for LocalVLLMProvider and OllamaProvider but requirements.txt omits it and scripts/verify_setup.py never checks for it, so fresh installs fail when local providers load.\n\nScope:\n- requirements.txt\n- scripts/verify_setup.py\n- src/models/local_model.py\n\nTasks:\n- Add requests\u003e=2.0.0 to requirements.txt under core dependencies.\n- Extend verify_setup.py verify_imports() to include (\"requests\", \"requests\") so missing requests surfaces.\n\nAcceptance:\n- After pip install -r requirements.txt, python scripts/verify_setup.py reports requests present.\n- Importing LocalVLLMProvider or OllamaProvider works without ImportError.","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-19T14:37:11.426828+08:00","updated_at":"2025-11-19T14:37:11.426828+08:00","source_repo":"."}
{"id":"moral_decision_consistency-thz","content_hash":"a2eab12d25e11e2b4858c0b88c7ae5c923d1a735fb253d03bbbb8e8790e74923","title":"Implement --models CLI override in run_experiment.py","description":"Priority: Medium-High\nArea: CLI script\n\nProblem:\nREADME advertises --models overrides and scripts/run_experiment.py defines the argument, but it never affects the run and --config is unimplemented, forcing config edits for every pilot tweak.\n\nScope:\n- scripts/run_experiment.py\n- README.md\n\nTasks:\n- Load experiment config via ConfigLoader in run_experiment.py, override models when --models is provided, and pass the resulting ExperimentConfig into runners instead of letting them reload.\n- Either implement basic --config support (alternate YAML path) or remove the flag/docs for now.\n- Update README examples to match the behavior.\n\nAcceptance:\n- python scripts/run_experiment.py --phase pilot --models qwen3-14b-q5 runs using only the provided model list.\n- CLI help and README usage reflect the implemented flags.","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-19T14:37:22.094766+08:00","updated_at":"2025-11-19T14:37:22.094766+08:00","source_repo":"."}
{"id":"moral_decision_consistency-ts4","content_hash":"b4596b9c09dd770820eee7300a68025aa2f8a0139be9fa3630f157d71f225053","title":"Implement Synthetic Internal Step Error (Type C) perturbation","description":"Priority: Backlog\nArea: Phase II experimentation, reasoning graphs, metrics\nReference: DECISIONS.md Synthetic Error Injection section\n\nProblem:\nPhase II calls for Perturbation Type C (Synthetic Internal Step Error) with structured reasoning steps, targeted error injection, repair prompts, and new metrics, but none of this exists yet.\n\nScope:\n- src/experiments/phase2_perturbation.py\n- src/data/schemas.py\n- src/analysis/metrics.py\n\nMinimal Spec:\n- Pass 1: prompt for 3-6 named steps with dependency edges and one-line claims (structured JSON).\n- Error injection: apply transforms (probability_swap, sign_flip, culpability_misattribution, premise_drop, numerical_offset) to a chosen step.\n- Pass 2: repair prompt instructing the model to find the mistake in Step k, minimally repair downstream steps, and re-decide outcome.\n- Metrics: localization accuracy, repair success, minimality score, counterfactual coherence, explanation-perturbation alignment.\n\nTasks:\n- Add Type C prompting + error injection pipeline to Phase2Runner and ReasoningGraph handling.\n- Log the second-pass repair data needed for metrics.\n- Extend metrics module to compute the Phase II measures for Type C runs.\n\nAcceptance:\n- Phase II can run with perturbation_types including synthetic_error to produce structured reasoning graphs, injected errors, and repair passes.\n- Analysis reports localization, repair success, minimality, and coherence metrics for those runs.","status":"open","priority":4,"issue_type":"task","created_at":"2025-11-19T14:37:56.035792+08:00","updated_at":"2025-11-19T14:37:56.035792+08:00","source_repo":"."}
